{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computational_neuroscience_ML_&_the_brain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPPrQCri4a6HyFPpe2GrGxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroFerreiradaCosta/Lectures/blob/master/Computational_neuroscience_ML_%26_the_brain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_z04nSlvA4"
      },
      "source": [
        "# Introduction to Computational Neuroscience\n",
        "\n",
        "## Day 2: Machine Learning and the brain\n",
        "\n",
        "### **Pedro Ferreira da Costa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii0yQFapl_za"
      },
      "source": [
        "In this tutorial we will work with brain imaging data from T1 scans.\n",
        "\n",
        "This tutorial is composed of three parts:\n",
        "1. You will build an Unsupervised Learning method from scratch\n",
        "2. You will explore and apply the machine learning library **scikit-learn**\n",
        "3. You will explore the deep learning library **tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtfgriZN_orK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5XooQA8mp0g"
      },
      "source": [
        "## Part 1 - Exploring the data and clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTzvwe0xEGMp"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzXuBCf2hEy"
      },
      "source": [
        "# Import dependencies\n",
        "import nibabel as nib # to load our .nii.gz files\n",
        "import matplotlib.pyplot as plt # to plot images\n",
        "\n",
        "from ipywidgets import interact # to create the sliders\n",
        "import numpy as np # library for mathematical python\n",
        "import skimage.measure # we use this library to downsample the brain data\n",
        "from google.colab import output # to clear the output\n",
        "import glob # to obtain the name of the files\n",
        "import random #Â useful for initializations\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yudd_f393MNN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQv7we0gmzzk"
      },
      "source": [
        "### Load data. How many values are included in each sample?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI_pnRaTC02_"
      },
      "source": [
        "# Download brain data we are using\n",
        "!wget -O brain_0.nii.gz https://www.dropbox.com/s/oy5w9z6ro4aj3gr/sample_0.nii.gz?dl=0\n",
        "!wget -O brain_1.nii.gz https://www.dropbox.com/s/8w3z96r9uqec8un/sample_1.nii.gz?dl=0\n",
        "!wget -O brain_2.nii.gz https://www.dropbox.com/s/j8tqkbq0tk9kw3g/sample_2.nii.gz?dl=0\n",
        "!wget -O brain_3.nii.gz https://www.dropbox.com/s/wt0i12tvnwyerto/sample_3.nii.gz?dl=0\n",
        "!wget -O brain_4.nii.gz https://www.dropbox.com/s/gftadh8wrhx35e0/sample_4.nii.gz?dl=0\n",
        "!wget -O brain_5.nii.gz https://www.dropbox.com/s/ldtu2kbjvxwbkxb/sample_5.nii.gz?dl=0\n",
        "!wget -O brain_6.nii.gz https://www.dropbox.com/s/bcqpu3sgw9ci2no/sample_6.nii.gz?dl=0\n",
        "!wget -O brain_7.nii.gz https://www.dropbox.com/s/3oktkjfykgcekjt/sample_7.nii.gz?dl=0\n",
        "!wget -O brain_8.nii.gz https://www.dropbox.com/s/vquuqejlcryitee/sample_8.nii.gz?dl=0\n",
        "!wget -O brain_9.nii.gz https://www.dropbox.com/s/v1f7j12qb7ae4rs/sample_9.nii.gz?dl=0\n",
        "!wget -O brain_10.nii.gz https://www.dropbox.com/s/ky70636u3dmbule/sample_10.nii.gz?dl=0\n",
        "!wget -O brain.nii.gz https://www.dropbox.com/s/9wfugvhuk1y9wq3/sample.nii.gz?dl=0\n",
        "\n",
        "#clear output so we can see the next print\n",
        "output.clear()\n",
        "\n",
        "# Load brain data\n",
        "brain  = nib.load('brain.nii.gz').get_fdata()\n",
        "\n",
        "print(f\"Each brain scan is an array of: {brain.shape}.\")\n",
        "print(f\"Or {brain.shape[0]*brain.shape[1]*brain.shape[2]} voxels.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDyZtQqCm7b-"
      },
      "source": [
        "### Let's visualize our brain data. Is there anything odd you see with out data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI2pC6vt3t_0"
      },
      "source": [
        "# Function that plots the brain at the desired slice\n",
        "def plot_brain(x, y, z):\n",
        "    x = np.clip(x, 0,191)\n",
        "    y = np.clip(y, 0,223)\n",
        "    z = np.clip(z, 0,191)\n",
        "\n",
        "    fig, ax = plt.subplots(1,3, figsize=(20,40))\n",
        "    ax[0].imshow(brain[x, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "    ax[1].imshow(brain[:, y, :].T, cmap=\"gray\", origin=\"lower\")\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "    ax[2].imshow(brain[:, :, z], cmap=\"gray\", origin=\"lower\")\n",
        "    ax[2].set_xticks([])\n",
        "    ax[2].set_yticks([])\n",
        "    return \n",
        "\n",
        "interact(plot_brain, x=69, y=83, z=105);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J614ns8Hjmxs"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY8acvyanKPB"
      },
      "source": [
        "### We need to work with a smaller representation of the data. Let's lower the data quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo7AudbyybHy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYFQQ4_m4Gsn"
      },
      "source": [
        "file_ls = glob.glob('*.nii.gz')\n",
        "brain_ls = []\n",
        "for file in file_ls:\n",
        "  tmp_brain  = nib.load(file).get_fdata()\n",
        "  brain_ls.append(skimage.measure.block_reduce(tmp_brain, (8,8,8), np.max))\n",
        "\n",
        "def plot_brain_reduced(n):\n",
        "  fig, ax = plt.subplots(1,3, figsize=(20,40))\n",
        "  ax[0].imshow(brain_ls[n][7, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
        "  ax[0].set_xticks([])\n",
        "  ax[0].set_yticks([])\n",
        "  ax[1].imshow(brain_ls[n][:, 10, :].T, cmap=\"gray\", origin=\"lower\")\n",
        "  ax[1].set_xticks([])\n",
        "  ax[1].set_yticks([])\n",
        "  ax[2].imshow(brain_ls[n][:, :, 13], cmap=\"gray\", origin=\"lower\")\n",
        "  ax[2].set_xticks([])\n",
        "  ax[2].set_yticks([])\n",
        "\n",
        "plot_brain_reduced(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgPDos1mwdJd"
      },
      "source": [
        "print(f\"Each brain scan is now an array of: {brain_ls[0].shape}.\")\n",
        "print(f\"Or {brain_ls[0].shape[0]*brain_ls[0].shape[1]*brain_ls[0].shape[2]} voxels.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A9rrVGWBa4A"
      },
      "source": [
        "### I want to find out if I can group them into separate clusters. \n",
        "#### What type of learning should I look into? What algorithms can I use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TUTuCh8SGub"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puzANQf9CBjd"
      },
      "source": [
        "Some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTm1E1HnKIe7"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "brain_np = np.array(brain_ls) \n",
        "# We re performing PCA in the list of brains, to try to visualize them in 2 dimensions\n",
        "pca = PCA(n_components=2)\n",
        "pca_brain = pca.fit_transform(brain_np.reshape(12, -1))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHyltfKjOH_M"
      },
      "source": [
        "\n",
        "def plot_cluster_map(centroid0, centroid1, assignements, i):\n",
        "  # This function generates a plot for us to better visualize how K-Means is performing\n",
        "  plt.figure()\n",
        "  plt.title(f\"Iteration {i}\")\n",
        "  colour=['red' if i == 0  else 'green' for i in assignements]\n",
        "  centroid0_pca = pca.transform(centroid0.reshape((1,-1)))\n",
        "  centroid1_pca = pca.transform(centroid1.reshape((1,-1)))\n",
        "\n",
        "  plt.scatter(pca_brain[:,0], pca_brain[:,1], c=colour)\n",
        "  plt.scatter(centroid0_pca[:, 0], centroid0_pca[:, 1],s=200, c='red', marker='X')\n",
        "  plt.scatter(centroid1_pca[:, 0], centroid1_pca[:, 1],s=200, c='green', marker='X')\n",
        "\n",
        "  plt.xlabel('1st Pricipal Component')\n",
        "  plt.ylabel('2nd Pricipal Component')\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvCP1Ao3SZJz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zs-10fCoY8G"
      },
      "source": [
        "### Let's try to code by ourselves the K-Means algorithm and apply it to our brain data. \n",
        "#### Follow the tips in the comments and remember - google is your friend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am6QX3Cn5bV3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgKLzV8zUNT0"
      },
      "source": [
        "\n",
        "# Flatten data\n",
        "brain_flatten = brain_np.reshape(12,-1)\n",
        "\n",
        "# Code a K-Means from scratch\n",
        "difference = np.random.rand(brain_flatten.shape[1]) * 255\n",
        "assignments = np.zeros(brain_np.shape[0]) # initializing the assignemnet of the clusters\n",
        "iteration=0 # just a counting variable\n",
        "\n",
        "\n",
        "##################### START HERE #####################\n",
        "# 1. Initialize centroids\n",
        "# Tip: Check random.choice() to initialize centroids in the place of one of the samples\n",
        "# centroid0 = ...\n",
        "# centroid1 = ...\n",
        "\n",
        "# 2. Repeat until convergence\n",
        "\n",
        "while(np.all(difference != np.zeros(brain_flatten.shape[1]))): # while the variable difference is not only zeros across every dimension. I.e., the centroid hasn't moved.\n",
        "    #    2.1 Assign every brain to the closest centroid\n",
        "    #    Tip: start by measuring the distances to both clusters for each brain. Use np.linalg.norm() for the euclidean distance\n",
        "\n",
        "    # assignements = ...\n",
        "\n",
        "    plot_cluster_map(centroid0, centroid1, assignements, iteration)\n",
        "    #    2.2 Update centroids\n",
        "\n",
        "\n",
        "\n",
        "    # Here we are updating the difference between iterations to check if the model converged    \n",
        "    # Do not change\n",
        "    difference = centroid0 - new_centroid0\n",
        "    centroid0 = new_centroid0\n",
        "    centroid1 = new_centroid1\n",
        "    iteration+=1\n",
        "    \n",
        "print(\"The algorithm has converged!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRd1Gzb-WR9e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Seo920owbO"
      },
      "source": [
        "## Part 2 - Using Scikit-learn for machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV7Sp27PemIz"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/PedroFerreiradaCosta/Lectures/master/tutorial/scikitlearn_homepage.png\" alt=\"FaceFitOpt Logo\" width=\"1000\">\n",
        "\n",
        "https://scikit-learn.org/stable/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHMeTd3ZpjLA"
      },
      "source": [
        "### Let's use scikit-learn's K-Means algorithm on our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-UYUOMYefRR"
      },
      "source": [
        "# Kmeans on the data - scikit learn\n",
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(n_clusters=2, random_state=2)\n",
        "assignements_sk = model.fit_predict(brain_np.reshape(12, -1))\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW8t-SQBTJDr"
      },
      "source": [
        "centroid0_sk = model.cluster_centers_[0,:]\n",
        "centroid1_sk = model.cluster_centers_[1,:]\n",
        "\n",
        "plot_cluster_map(centroid0_sk, centroid1_sk, assignements_sk, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJeRMUCBpqFs"
      },
      "source": [
        "### Are the results different from our implementation? Are the clusters meaningful?\n",
        "#### Let's look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnQjDMMNxSwK"
      },
      "source": [
        "# Compare with previous results\n",
        "plot_cluster_map(centroid0, centroid1, assignements, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cp-HxMWqaC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO0RD_n8q1UL"
      },
      "source": [
        "## Let's now look into Supervised Learning\n",
        "### Because we are trying to classify our brains between two categories we will use Logistic regression. \n",
        "### What is logistic regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNyci5MArybH"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/PedroFerreiradaCosta/Lectures/master/tutorial/logistic_reg.png\" alt=\"FaceFitOpt Logo\" width=\"500\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/PedroFerreiradaCosta/Lectures/master/tutorial/sigmoid.png\" alt=\"FaceFitOpt Logo\" width=\"500\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGiYKpHJxgWl"
      },
      "source": [
        "# Logistic Regression with labelled outputs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "y = [0,0,0,1,1,1,0,0,0,0,0,1]\n",
        "# Flatten data\n",
        "brain_flatten = brain_np.reshape(12,-1)\n",
        "# Split data into train and test\n",
        "\n",
        "# Instantiate logistic regression\n",
        "\n",
        "# Train the model\n",
        "\n",
        "# Score\n",
        "\n",
        "\n",
        "# Plot metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UgYgjuT58KI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_r77S0ZsNKl"
      },
      "source": [
        "## Part 3 - Using Tensorflow to apply deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqkUwufEsmGD"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/PedroFerreiradaCosta/Lectures/master/tutorial/tensorflow.png\" alt=\"FaceFitOpt Logo\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM9aVQpkzjSq"
      },
      "source": [
        "https://www.tensorflow.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7HxipHys03p"
      },
      "source": [
        "### We will be creating an autoencoder and will try to reconstruct coronal slides of our brain data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoIfgQ7sssi4"
      },
      "source": [
        "#### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e1fhRQDxNLb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHxv4IOJsv2v"
      },
      "source": [
        "#### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaeHl7Th1wmn"
      },
      "source": [
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(576, activation='sigmoid'),\n",
        "      layers.Reshape((24, 24))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    print(encoded)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymijmox8s92b"
      },
      "source": [
        "#### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtoBjCR91yel"
      },
      "source": [
        "latent_dim = 20\n",
        "autoencoder = Autoencoder(latent_dim)\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G5kwQgStCWa"
      },
      "source": [
        "#### Let's consider the coronal plane as 2D images for our Auto-encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqf6eDf87r9Z"
      },
      "source": [
        "X = [brain_ls[i][:,j,:] / 255 for i in range(len(brain_ls)) for j in range(brain_ls[i].shape[1])]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=42)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV8sbB82DYB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fa66f7-e59b-4823-e5d3-80d3fef8106a"
      },
      "source": [
        "print(f\"{len(X_train)} samples will be used for training.\")\n",
        "print(f\"{len(X_val)} samples will be used for validation.\")\n",
        "print(f\"{len(X_test)} samples will be used for testing.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "214 samples will be used for training.\n",
            "54 samples will be used for validation.\n",
            "68 samples will be used for testing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZVBngOUtJEB"
      },
      "source": [
        "#### Train the model - why both X_train?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUvSFZF_113u"
      },
      "source": [
        "\n",
        "history = autoencoder.fit(np.array(X_train), np.array(X_train),\n",
        "                batch_size=10,\n",
        "                epochs=200,\n",
        "                shuffle=True,\n",
        "                validation_data=(np.array(X_val), np.array(X_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl9tSU1QtL0E"
      },
      "source": [
        "#### Let's plot the error progression across training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg9Rhv_PRJST"
      },
      "source": [
        "\n",
        "plt.plot(range(200), history.history['loss'], label='training loss')\n",
        "plt.plot(range(200), history.history['val_loss'], label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9i0p3HLLbtA"
      },
      "source": [
        "results = autoencoder.evaluate(np.array(X_test), np.array(X_test), batch_size=10)\n",
        "print(f\"Loss in the test set is {results}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBrFQv1fND4F"
      },
      "source": [
        "encoded_imgs = autoencoder.encoder(np.array(X_test)).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRi8VxfQtPou"
      },
      "source": [
        "#### Let's plot how the autoencoder performed on unseen data (test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA8ZLhxnDlH0"
      },
      "source": [
        "\n",
        "def plot_results(sample):\n",
        "    sample = np.clip(sample, 0, 67)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(20,40))\n",
        "    ax[0].imshow(np.array(X_test)[sample, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "    ax[1].imshow(decoded_imgs[sample, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "\n",
        "    print(\"576 values were reduced to these 20 values:\")\n",
        "    print(encoded_imgs[sample, :])\n",
        "    return \n",
        "\n",
        "interact(plot_results, sample=34);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnp11ZQwLV_b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}